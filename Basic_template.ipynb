{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6x3kdY5mDWw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Step 1: Data Gathering and Cleaning\n",
        "df1 = pd.read_csv('dataset1.csv')\n",
        "df2 = pd.read_csv('dataset2.csv')\n",
        "# ... Load other datasets\n",
        "\n",
        "# Data cleaning steps as needed\n",
        "# ...\n",
        "\n",
        "# Step 2: Data Preprocessing\n",
        "df = pd.concat([df1, df2], axis=0)  # Merge datasets if needed\n",
        "\n",
        "# Handle missing values\n",
        "df = df.dropna()\n",
        "\n",
        "#check for outliers\n",
        "for col in numerical_features:\n",
        "  sns.boxplot(data = df, x = col  )\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "# Handle outliers\n",
        "column_name = 'feature_data'\n",
        "z_scores = np.abs((df[column_name] - df[column_name].mean()) / df[column_name].std())\n",
        "threshold = 3\n",
        "filtered_df = df[z_scores < threshold]\n",
        "\n",
        "\n",
        "# Feature engineering\n",
        "df['new_feature'] = df['feature1'] + df['feature2']\n",
        "df = df.drop(['irrelevant_feature1', 'irrelevant_feature2'], axis=1)\n",
        "\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "#drop highly correlated features\n",
        "upper = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(np.bool))\n",
        "\n",
        "correlated_to_drop = []\n",
        "for col in upper.columns:\n",
        "    if any(upper[col] > 0.9):\n",
        "        correlated_to_drop.append(col)\n",
        "        \n",
        "nba_reg_new.drop(correlated_to_drop, axis=1, inplace=True)\n",
        "\n",
        "\n",
        "# Select numerical features\n",
        "numerical_features = df.select_dtypes(include=['number'])\n",
        "\n",
        "# Select categorical features\n",
        "categorical_features = df.select_dtypes(include=['object'])\n",
        "\n",
        "# Define the numerical and categorical feature column names\n",
        "num_features = numerical_features.columns.tolist()\n",
        "cat_features = categorical_features.columns.tolist()\n",
        "\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X = df.drop('target_variable', axis=1)\n",
        "y = df['target_variable']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_dev, X_test, y_dev, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "\n",
        "\n",
        "# Create the column transformer for preprocessing\n",
        "preprocess = make_column_transformer(\n",
        "    (StandardScaler(), num_features),\n",
        "    (OneHotEncoder(handle_unknown='ignore'), cat_features),\n",
        "    \n",
        ")\n",
        "\n",
        "# Fit and transform the training data\n",
        "X_dev_preprocessed = preprocess.fit_transform(X_dev)\n",
        "\n",
        "# Transform the test data using the fitted transformer\n",
        "X_test_preprocessed = preprocess.transform(X_test)\n",
        "\n",
        "\n",
        "\n",
        "# Step 3: Data Visualization\n",
        "# Explore the data through visualizations\n",
        "# ...\n",
        "\n",
        "# Step 4: Trying Multiple ML Models and Hyperparameter Tuning\n",
        "# Instantiate the models\n",
        "logreg = LogisticRegression()\n",
        "dtree = DecisionTreeClassifier()\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "# Define the hyperparameter grids to search over\n",
        "logreg_params = {'C': [0.1, 1, 10]}\n",
        "dtree_params = {'max_depth': [None, 5, 10], 'min_samples_split': [2, 5, 10]}\n",
        "rf_params = {'n_estimators': [100, 200, 300], 'max_depth': [None, 5, 10]}\n",
        "\n",
        "# Perform hyperparameter tuning using GridSearchCV\n",
        "logreg_grid = GridSearchCV(logreg, logreg_params, cv=5)\n",
        "logreg_grid.fit(X_dev_preprocessed, y_train)\n",
        "\n",
        "dtree_grid = GridSearchCV(dtree, dtree_params, cv=5)\n",
        "dtree_grid.fit(X_train, y_train)\n",
        "\n",
        "rf_grid = GridSearchCV(rf, rf_params, cv=5)\n",
        "rf_grid.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters and evaluation scores\n",
        "print(\"Logistic Regression:\")\n",
        "print(\"Best Hyperparameters:\", logreg_grid.best_params_)\n",
        "print(\"Cross-validation Score:\", logreg_grid.best_score_)\n",
        "\n",
        "print(\"Decision Tree:\")\n",
        "print(\"Best Hyperparameters:\", dtree_grid.best_params_)\n",
        "print(\"Cross-validation Score:\", dtree_grid.best_score_)\n",
        "\n",
        "print(\"Random Forest:\")\n",
        "print(\"Best Hyperparameters:\", rf_grid.best_params_)\n",
        "print(\"Cross-validation Score:\", rf_grid.best_score_)\n",
        "\n",
        "# Select the best-performing model based on the evaluation results\n",
        "best_model = rf_grid.best_estimator_\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "accuracy = best_model.score(X_test, y_test)\n",
        "print(\"Test Accuracy:\", accuracy)"
      ]
    }
  ]
}